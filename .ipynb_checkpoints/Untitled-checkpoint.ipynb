{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using LeNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgShape = (28, 28, 3)\n",
    "classes = 3\n",
    "model = Sequential()\n",
    "# First set of CONV => RELU => POOL layers\n",
    "model.add(Conv2D(20, (5, 5),input_shape=imgShape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Second set of CONV => RELU => POOL layers\n",
    "model.add(Conv2D(50, (5, 5)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Set of FC => RELU layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation(\"relu\"))\n",
    " \n",
    "# Softmax classifier\n",
    "model.add(Dense(classes))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "compile_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the necessary packages for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiailize epoch, learning rate, and batches\n",
    "EPOCH = 4\n",
    "INIT_LR = 0.0001\n",
    "BS = 125\n",
    "PATH = 'C:\\\\Users\\\\Administrator\\\\RPS\\\\dataset\\\\train'\n",
    "train_path = PATH+\"\\\\train\"\n",
    "test_path = PATH+\"\\\\test\"\n",
    "\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = sorted(list(paths.list_images(PATH)))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (28, 28))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    " \n",
    "    # extract the class label from the image path and update the\n",
    "    # labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    #print(label)\n",
    "    if label == \"paper\":\n",
    "        label = 0\n",
    "    elif label == \"rock\":\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 2\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.1, random_state=42)\n",
    " \n",
    "trainY = to_categorical(trainY, num_classes=3)\n",
    "testY = to_categorical(testY, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "trainImg_gen = ImageDataGenerator(\n",
    "    rotation_range = 180.,\n",
    "    vertical_flip = True,\n",
    "    horizontal_flip = True)\n",
    "\n",
    "testImg_gen = ImageDataGenerator(\n",
    "    rotation_range = 180.,\n",
    "    vertical_flip = True,\n",
    "    horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Train this CNNs model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1350/1350 [==============================] - 254s 188ms/step - loss: 0.0978 - acc: 0.9682 - val_loss: 0.0578 - val_acc: 0.9867\n",
      "Epoch 2/4\n",
      "1350/1350 [==============================] - 243s 180ms/step - loss: 0.0200 - acc: 0.9938 - val_loss: 0.0693 - val_acc: 0.9800\n",
      "Epoch 3/4\n",
      "1350/1350 [==============================] - 243s 180ms/step - loss: 0.0123 - acc: 0.9962 - val_loss: 0.0154 - val_acc: 0.9867\n",
      "Epoch 4/4\n",
      "1350/1350 [==============================] - 245s 182ms/step - loss: 0.0089 - acc: 0.9972 - val_loss: 0.0405 - val_acc: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1be66716710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(trainImg_gen.flow(trainX, trainY, batch_size=BS),validation_data=(testX, testY), \n",
    "                    steps_per_epoch=len(trainX),epochs=EPOCH, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"myModel02.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
